model_name: gpt-3.5-turbo-0125 # Model name used to generate the translation. It can be an OpenAI model or an huggingface model.
transcript_path: transcripts_examples/fr/deuxieme_loi_de_newton_les_bons_profs.txt # Path to the .txt transcript. To get an example you can get the generated subtitles from a youtube video.
metadata_path: results/metadata_gpt-35_fr_newton.json
quizzes_path: results/quizzes_gpt-35_fr_newton.jsonl
notes_path: results/notes_gpt-35_fr_newton.txt
from_language: fr
to_language: en
output_path: results/translation_gpt-35_fr_newton.txt # Translation output path
connector: # Configuration of the connector. You can use the CustomOpenAIConnector for OpenAI and APIConnectorWithOpenAIFormat for HuggingFace models deployed with vLLM
  (): "aristote.connectors.connectors.CustomOpenAIConnector"
  cache_path: .cache_gpt-35
  max_requests_per_second: 30
prompts_config: # Prompts configuration. Paths to each prompt saved as .txt file.
  (): "aristote.translation_generation.translation_generator.TranslationPromptsConfig"
  title_translation_prompt_path: aristote/translation_generation/prompts/mistral/english/title_translation_prompt.txt
  description_translation_prompt_path: aristote/translation_generation/prompts/mistral/english/description_translation_prompt.txt
  topics_translation_prompt_path: aristote/translation_generation/prompts/mistral/english/topics_translation_prompt.txt
  quiz_translation_prompt_path: aristote/translation_generation/prompts/mistral/english/quiz_translation_prompt.txt
  transcript_translation_prompt_path: aristote/translation_generation/prompts/mistral/english/transcript_translation_prompt.txt
  notes_translation_prompt_path: aristote/translation_generation/prompts/mistral/english/notes_translation_prompt.txt
